{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36313947-eebf-477e-b2b6-6d0c7d0b83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aerolib import *\n",
    "from xfoillib import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d2407d-94a1-4262-b4d3-0c38e39c70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    return num != num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae45f23-6125-4afb-b053-a735ba85aaba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InsufficientInputData(Exception):\n",
    "    def __init__(self, text):\n",
    "        self.txt = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e02419-69b8-42a3-9078-65895a3d2b84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Foil():\n",
    "    def __init__(self, name):\n",
    "        pass\n",
    "    def get_geometry(self):\n",
    "        pass\n",
    "    def get_filename(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76409a66-b03a-4e4b-85d5-c325cbf43295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sculptor():\n",
    "    def __init__(self, performance_file_name, params_file_name, settings_file_name, m):\n",
    "        self.params_file_name = params_file_name\n",
    "        self.geom_file_name = \"GEOM.csv\"\n",
    "        self.aero_file_name = \"AERO.csv\"\n",
    "        df = pd.read_csv(performance_file_name, header=None)[1:]\n",
    "        self.performance = dict(zip(df[0], [float(x) for x in df[1]]))\n",
    "        self.preprocess_performance()\n",
    "\n",
    "        df = pd.read_csv(settings_file_name, header=None)[1:]\n",
    "        self.settings = dict(zip(df[0], [x for x in df[1]]))\n",
    "        self.preprocess_settings()\n",
    "\n",
    "        df=pd.read_csv(params_file_name, index_col=False)\n",
    "        self.params = dict(filter(lambda x: x[0][0]!=\"#\", dict(zip(df[\"NAME\"], [float(x) for x in df[\"VALUE\"]])).items()))\n",
    "        self.preprocess_params()\n",
    "\n",
    "        self.geom = {}\n",
    "        self.aero = {\"cruise\":np.nan}\n",
    "        self.tom = m\n",
    "\n",
    "    def preprocess_params(self):\n",
    "        critical_params = ['CL_take_off', 'eta_prop', 'A_aft', \n",
    "                           'B_keel', 'l_stab']\n",
    "        for name in critical_params:\n",
    "            if isNaN(self.params.get(name, np.nan)):\n",
    "                raise InsufficientInputData(f'obligatory parametr {name} not found')\n",
    "\n",
    "    def preprocess_performance(self):\n",
    "        critical_performance = ['cruise_speed', 'take_off_speed', 'flight_time']\n",
    "        for name in critical_performance:\n",
    "            if isNaN(self.performance.get(name, np.nan)):\n",
    "                raise InsufficientInputData(f'obligatory parametr {name} not found')\n",
    "    \n",
    "    def preprocess_settings(self):\n",
    "        if isNaN(self.settings.get('g', np.nan)):\n",
    "            self.settings['g'] = 9.81\n",
    "            \n",
    "        if isNaN(self.settings.get('density', np.nan)):\n",
    "            self.settings['density'] = 1.22\n",
    "\n",
    "        if isNaN(self.settings.get('wire_scale_coef', np.nan)):\n",
    "            self.performance['wire_scale_coef'] = 1.3\n",
    "        \n",
    "        critical_settings = ['dyn_viscosity', 'density', 'g', 'Re', 'M', \n",
    "                             'xfoil_max_it', 'ncr', 'alpha_min', 'alpha_max', 'alpha_step', \n",
    "                             'ar_min', 'ar_max', 'ar_delta', 'osvald_coef', \n",
    "                             'wire_scale_coef', 'XFoil_path', 'foil1_name', 'work_dir']\n",
    "        for name in critical_settings:\n",
    "            if isNaN(self.settings.get(name, np.nan)):\n",
    "                raise InsufficientInputData(f'obligatory parametr {name} not found')\n",
    "\n",
    "    def calculate_geometry(self):        \n",
    "        self.geom[\"wing_area\"] = wing_area(self.tom, float(self.settings[\"g\"]),\n",
    "                                           float(self.settings[\"density\"]), \n",
    "                                           float(self.performance[\"take_off_speed\"]), \n",
    "                                           float(self.params[\"CL_take_off\"]))\n",
    "        self.CL_cr = CL_cruise(self.tom, self.performance[\"cruise_speed\"],\n",
    "                               float(self.geom[\"wing_area\"]), float(self.settings[\"g\"]), \n",
    "                               float(self.settings[\"density\"]))\n",
    "        ar_step_number = int(abs(float(self.settings[\"ar_max\"]) - float(self.settings[\"ar_min\"])) // float(self.settings[\"ar_delta\"]))\n",
    "        \n",
    "        ar_range = np.linspace(float(self.settings[\"ar_min\"]), float(self.settings[\"ar_max\"]), ar_step_number)\n",
    "        \n",
    "        self.geom[\"AR\"] = AR_selector(ar_range, self.geom, \n",
    "                                      self.settings, self.performance, self.tom)\n",
    "        self.aero[\"cruise\"] = K_V_solver(self.geom, self.settings, \n",
    "                                         self.performance[\"cruise_speed\"], \n",
    "                                         self.geom[\"AR\"], self.tom)\n",
    "        self.geom[\"ba\"] = ba(self.geom[\"AR\"], self.geom[\"wing_area\"])\n",
    "        self.geom[\"wingspan\"] = wingspan(self.geom[\"AR\"], self.geom[\"wing_area\"])\n",
    "        self.geom[\"foil1_perimeter\"] = calc_foil_perimeter(settings[\"foil1_name\"])\n",
    "        self.geom[\"aft_area\"] = aft_area(float(self.params[\"A_aft\"]), \n",
    "                                         self.geom[\"wing_area\"], self.geom[\"ba\"], \n",
    "                                         float(self.params[\"l_stab\"]))\n",
    "        self.geom[\"keel_area\"] = keel_area(float(self.params[\"B_keel\"]), \n",
    "                                           self.geom[\"wing_area\"], self.geom[\"wingspan\"], \n",
    "                                           float(self.params[\"l_stab\"]))\n",
    "        self.geom[\"V_dihedral\"] = gamma(self.geom[\"keel_area\"], self.geom[\"aft_area\"])\n",
    "        self.geom[\"Vtail_area\"] = stab_area(self.geom[\"aft_area\"], self.geom[\"V_dihedral\"])\n",
    "        self.geom[\"P_cruise\"] = P_cruise(self.tom, self.aero[\"cruise\"].K[0], \n",
    "                                        float(self.params[\"eta_prop\"]), float(self.settings[\"g\"]))\n",
    "        self.geom[\"wire_length\"] = wire_length(self.geom[\"wingspan\"], float(self.params[\"l_stab\"]), \n",
    "                                              float(self.settings[\"wire_scale_coef\"]))\n",
    "\n",
    "        self.geom[\"V_dihedral\"] = math.degrees(gamma(self.geom[\"keel_area\"], self.geom[\"aft_area\"]))\n",
    "        \n",
    "        return 0\n",
    "        \n",
    "    def update_m(self, new_m):\n",
    "        self.tom = new_m\n",
    "    \n",
    "    def write_geom(self):\n",
    "        with open(self.geom_file_name, 'w') as f:\n",
    "            f.write(\"%s, %s\\n\" % (\"NAME\", \"VALUE\"))\n",
    "            for key in self.geom.keys():\n",
    "                f.write(\"%s, %s\\n\" % (key, self.geom[key]))\n",
    "    \n",
    "    def write_aero(self):\n",
    "        with open(self.aero_file_name, 'w') as f:\n",
    "            f.write(\"%s, %s\\n\" % (\"NAME\", \"VALUE\"))\n",
    "            for key in self.aero.keys():\n",
    "                f.write(\"%s, %s\\n\" % (key, self.aero[key]))\n",
    "    \n",
    "    def write_info(self):\n",
    "        self.write_geom()\n",
    "        self.write_aero()\n",
    "        \n",
    "        \n",
    "\n",
    "    def get_data_to_weigh(self):\n",
    "        return [self.params_file_name, self.geom_file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56061eb7-ad38-440e-a725-ed9f02dd5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "Ожидаемый формат params-csv-файла\n",
    "NAME  INDEX  VALUE CONJUGATE\n",
    "0   m1    1      1            NaN\n",
    "1   n1    1     10            NaN\n",
    "2   m2    2      2            NaN\n",
    "3   n2    2    100            NaN\n",
    "4   m3    NaN      3            NaN\n",
    "5    m    NaN   1000             cy\n",
    "\n",
    "Ожидаемый формат geomerty-csv-файла\n",
    "NAME      VALUE\n",
    "wing_area 1\n",
    "ba        1\n",
    "wingspan  1\n",
    "AR        1\n",
    "'''\n",
    "\n",
    "#m (масса ЛА) -- есть сумма\n",
    "#слагаемые бывают трёх типов:\n",
    "#1) произведение величин из params с одинаковым индексом\n",
    "#2) произведение двух величин -- одна из params, одна из geometry (её имя - CONJUGATE)\n",
    "#3) величина из params\n",
    "def weigh(params_file_name, geometry_file_name, ask_about_no_value=True):\n",
    "    geom_df = pd.read_csv(geometry_file_name, header=None).loc[1:] #удаление заголовка из DF\n",
    "    geom = dict(zip(geom_df[0], geom_df[1])) #создание словаря {Cy: <val>, ...}\n",
    "\n",
    "    #создание таблицы с колонками вида \n",
    "    #[<colomn_num>, <NAME>, <INDEX>, <VALUE>, <CONJUGATE>]\n",
    "    params = pd.read_csv(params_file_name, index_col=False) \n",
    "    params = pd.DataFrame(filter(lambda x: x[\"NAME\"][0] != \"#\", [params.iloc[i] for i in range(len(params.axes[0]))])).T\n",
    "    \n",
    "    #создание словаря \n",
    "    #{<значение колонки index из params>: <список значений всех параметров с этим индексом>}\n",
    "    multiply_dict = dict()\n",
    "    multiply_dict_names = dict()\n",
    "    m = 0\n",
    "    \n",
    "    for var in params: #итерация по колонкам; в var попадает номер колонки (colomn_num)\n",
    "        params[var][\"VALUE\"] = float(params[var][\"VALUE\"])\n",
    "        if isNaN(params[var][\"VALUE\"]):\n",
    "            if ask_about_no_value:\n",
    "                ans = input(f\"\\nУ ПАРАМЕТРА {params[var]['NAME']} нет значения - пропустить (y/n)?\")\n",
    "            else:\n",
    "                ans = \"y\"\n",
    "            if ans == \"y\":\n",
    "                continue\n",
    "            raise InsufficientInputData(f\"no value for variable '{params[var]['NAME']}'\")\n",
    "\n",
    "        if not isNaN(params[var][\"INDEX\"]): #если тип (1)\n",
    "            #создать в multiply_dict ключ с найденым индексом,\n",
    "            #со значением пустого списка, если такого ключа ещё нет\n",
    "            multiply_dict[params[var][\"INDEX\"]] = multiply_dict.get(params[var][\"INDEX\"], [])\n",
    "            multiply_dict_names[params[var][\"INDEX\"]] = multiply_dict_names.get(params[var][\"INDEX\"], [])\n",
    "            #добавить значение этого параметра\n",
    "            #в список индекса найденного индекса\n",
    "            multiply_dict[params[var][\"INDEX\"]].append(params[var][\"VALUE\"])\n",
    "            multiply_dict_names[params[var][\"INDEX\"]].append(params[var][\"NAME\"])\n",
    "        \n",
    "        elif not isNaN(params[var][\"CONJUGATE\"]): #если тип (2)\n",
    "            conjugates_list = \"\".join(params[var][\"CONJUGATE\"].split()).split(\",\")\n",
    "            try:\n",
    "                conjugates = list(map(lambda conj: 1/float(geom[conj[2:]]) if conj[0:2] == \"1/\" else float(geom[conj]), conjugates_list))\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                raise InsufficientInputData(f\"for variable '{params[var]['NAME']}', '{params[var]['CONJUGATE']}' \"+\\\n",
    "                                                f\"is specified as conjugate, but it is no '{params[var]['CONJUGATE']}'\"+\\\n",
    "                                                f\" in the geom-file\")\n",
    "            for conj in conjugates:\n",
    "                m += conj * params[var][\"VALUE\"]\n",
    "            print(f\"+ {params[var]['NAME']}*\", \"*\".join(conjugates_list), \" : \",  m, sep=\"\")\n",
    "            \n",
    "\n",
    "    #вычисление слагаемых типа (1) -- перемножение значения параметров с одинаковыми индексами\n",
    "    for item in multiply_dict.items():\n",
    "        key, vals = item\n",
    "        m += math.prod(vals)\n",
    "        print(\"+\", \"*\".join(multiply_dict_names[key]) , \":\",  m)\n",
    "    \n",
    "    print(f\"------------------------\\nИтоговая масса: {m}\\n------------------------\\n\\n\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812f2fd3-5659-401b-a19a-9b4c58c7911e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Модуль расчёта геометрических характеристик потребляет на вход: \n",
    "# dataframe PERFORMANCE с потребными эксплуатационными характеристиками\n",
    "# dataframe PARAMS с параметрами электронных компонент, конструкционных материалов, аккумуляторов и т.д.\n",
    "# пути до файлов селиговского формата с профилем крыла wing_foil и с профилем оперения aft_foil.\n",
    "# TOM - значение взлётной массы в начальном приближении.\n",
    "\n",
    "# PERFORMANCE включает параметры take_off_speed, cruise_speed, flight_time, payload\n",
    "\n",
    "# PARAMS включает параметры m_FPV, m_powerplant, m_flight_control, m_fus, m_servo1, m_servo2,\n",
    "# line_dens_wire, line_dens_tube1, line_dens_tube2, line_dens_tube3,\n",
    "# area_dens_LWPLA\n",
    "# energy_dens_bat\n",
    "# number_servo1, number_servo2\n",
    "# l_stab\n",
    "\n",
    "# Все единицы в СИ\n",
    "def inner_iteration():\n",
    "    performance_file_name = \"PERFORMANCE.csv\"#input(\"имя файла performances: \")\n",
    "    params_file_name = \"PARAMS.csv\" #input(\"имя файла params: \")\n",
    "    settings_file_name = \"SETTINGS.csv\" #input(\"имя файла settings: \") \n",
    "    tom = 2 #input(\"нулевое приближение влётной массы: \")\n",
    "    max_iter = 10 #input(\"максимальное число итераций: \")\n",
    "    \n",
    "    df = pd.read_csv(settings_file_name, header=None)\n",
    "    tom_eps = float(dict(zip(df[0], df[1]))[\"tom_eps\"])\n",
    "    \n",
    "    sculptor = Sculptor(performance_file_name, params_file_name, settings_file_name, tom)\n",
    "    i = 1\n",
    "    ask_about_no_value = True\n",
    "    while True:\n",
    "        sculptor.calculate_geometry()\n",
    "        sculptor.write_info()\n",
    "        pf, gf = sculptor.get_data_to_weigh()\n",
    "\n",
    "        print(f\"итерация {i}\")\n",
    "        new_tom = weigh(pf, gf, ask_about_no_value)\n",
    "        ask_about_no_value = False\n",
    "        if abs(tom - new_tom) > tom_eps:\n",
    "            tom = new_tom\n",
    "            sculptor.update_m(new_tom)\n",
    "        else:\n",
    "            print(f\"сошлось на итерации: {i}\")\n",
    "            print(\"информация сохранена в файл с геометрией\")\n",
    "            break\n",
    "        \n",
    "        if i == max_iter:\n",
    "            print(f\"прошло {i} итераций, но расчёт всё ещё не завершён.\")\n",
    "            flag = 2\n",
    "            while flag not in ['0', '1']:\n",
    "                flag = input(f\"введите 1, чтобы произвести ещё {max_iter} операций, иначе 0: \")\n",
    "            if flag:\n",
    "                i = 0\n",
    "            else:\n",
    "                print(\"последняя итерация геометрии сохранена\")\n",
    "                break\n",
    "            \n",
    "        i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c60f5c-e353-43b9-80fa-20c59c3275e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 4 fields in line 42, saw 6\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minner_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m, in \u001b[0;36minner_iteration\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(settings_file_name, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m tom_eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;241m0\u001b[39m], df[\u001b[38;5;241m1\u001b[39m]))[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtom_eps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 27\u001b[0m sculptor \u001b[38;5;241m=\u001b[39m \u001b[43mSculptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperformance_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msettings_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     29\u001b[0m ask_about_no_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36mSculptor.__init__\u001b[1;34m(self, performance_file_name, params_file_name, settings_file_name, m)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;241m0\u001b[39m], [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;241m1\u001b[39m]]))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_settings()\n\u001b[1;32m---> 14\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m]]))\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_params()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 4 fields in line 42, saw 6\n"
     ]
    }
   ],
   "source": [
    "inner_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc0ddc1-c651-4624-a192-a788eb5ffc93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54b56f-2e83-41da-b502-febbc5b88cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
